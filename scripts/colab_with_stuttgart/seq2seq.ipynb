{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4ICFYQybvuG",
    "outputId": "6c0559aa-f606-4343-c855-110690463004"
   },
   "source": [
    "!pip install tensorflow numpy pandas dd pyeda"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "id": "vIdiKH4Ib112"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Read the CSV data\n",
    "data = pd.read_csv('inputs_2exp17.csv') # 131,072\n",
    "\n",
    "# Data processing\n",
    "expressions = data['expression'].tolist()\n",
    "reorderings = data['reordering'].tolist()"
   ],
   "metadata": {
    "id": "So3Dsv32b9kH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(data[10:15])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zPg95uzcWXq",
    "outputId": "587f7290-b0a3-4d0c-e0c6-5308bf15bb28"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   expression ordering  bdd_size reordering  bdd_size_reordered\n",
      "10    c|d|a&f  d:f:a:c        10    d:f:a:c                   5\n",
      "11    c|b&f&e  f:e:c:b        11    e:f:b:c                   5\n",
      "12    a|c|e&f  a:e:f:c        10    a:e:f:c                   5\n",
      "13    f|b|c|e  b:c:f:e        11    c:b:f:e                   5\n",
      "14    b|a&d|d    a:d:b         7      a:d:b                   3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Prepare the tokenizers\n",
    "# For input expressions (characters)\n",
    "input_tokenizer = Tokenizer(char_level=True, filters='')\n",
    "input_tokenizer.fit_on_texts(expressions)\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1  # +1 for padding token\n",
    "print(input_tokenizer.word_index)\n",
    "\n",
    "# For output reorderings (tokens separated by ':')\n",
    "# We will replace ':' with space to tokenize the variables\n",
    "target_texts = []\n",
    "for seq in reorderings:\n",
    "    # Add start and end tokens for the decoder\n",
    "    target_texts.append('<start> ' + seq.replace(':', ' ') + ' <end>')\n",
    "\n",
    "# Prepare tokenizer for outputs\n",
    "output_tokenizer = Tokenizer(filters='')\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1  # +1 for padding token\n",
    "print(input_vocab_size, output_vocab_size)\n",
    "print(target_texts)\n",
    "print(output_tokenizer.word_index)"
   ],
   "metadata": {
    "id": "yRGgG_Uickrt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9d7ac9c1-34d1-4bc4-f820-840ed69e7ee8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert expressions and reorderings to sequences\n",
    "encoder_input_sequences = input_tokenizer.texts_to_sequences(expressions)\n",
    "\n",
    "decoder_input_texts = []\n",
    "decoder_target_texts = []\n",
    "for seq in reorderings:\n",
    "    decoder_input_texts.append('<start> ' + seq.replace(':', ' '))\n",
    "    decoder_target_texts.append(seq.replace(':', ' ') + ' <end>')\n",
    "\n",
    "decoder_input_sequences = output_tokenizer.texts_to_sequences(decoder_input_texts)\n",
    "decoder_target_sequences = output_tokenizer.texts_to_sequences(decoder_target_texts)\n",
    "print(decoder_input_sequences[0:3])\n",
    "print(decoder_target_sequences[0:3])\n",
    "\n",
    "# Determine the maximum sequence lengths\n",
    "max_encoder_seq_length = max([len(seq) for seq in encoder_input_sequences])\n",
    "max_decoder_seq_length = max([len(seq) for seq in decoder_input_sequences])\n",
    "print(max_encoder_seq_length, max_decoder_seq_length)\n",
    "\n",
    "# Pad the sequences\n",
    "encoder_input_data = pad_sequences(encoder_input_sequences, maxlen=max_encoder_seq_length, padding='post')\n",
    "decoder_input_data = pad_sequences(decoder_input_sequences, maxlen=max_decoder_seq_length, padding='post')\n",
    "decoder_target_data = pad_sequences(decoder_target_sequences, maxlen=max_decoder_seq_length, padding='post')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaLxbY_bcp2c",
    "outputId": "3b39a9be-db3a-44bf-8b7c-7dc246dc3f63"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1, 7, 6, 4], [1, 3, 8, 7, 6], [1, 8, 3, 7, 6]]\n",
      "[[7, 6, 4, 2], [3, 8, 7, 6, 2], [8, 3, 7, 6, 2]]\n",
      "9 5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the embedding dimension and latent dimension\n",
    "embedding_dim = 50\n",
    "latent_dim = 256\n",
    "\n",
    "# Build the encoder\n",
    "encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "enc_emb = Embedding(input_dim=input_vocab_size, output_dim=embedding_dim, name='encoder_embedding')(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Build the decoder\n",
    "decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "dec_emb_layer = Embedding(input_dim=output_vocab_size, output_dim=embedding_dim, name='decoder_embedding')\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn encoder_input_data & decoder_input_data into decoder_target_data\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Add an additional dimension to decoder_target_data for sparse_categorical_crossentropy\n",
    "decoder_target_data = np.expand_dims(decoder_target_data, -1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    validation_split=0.2\n",
    ")"
   ],
   "metadata": {
    "id": "1MSfb9aZcymZ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "066f79b0-8823-4388-aebb-b9bc7f5e2660"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m99s\u001B[0m 117ms/step - loss: 1.0978 - val_loss: 0.4809\n",
      "Epoch 2/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m139s\u001B[0m 114ms/step - loss: 0.4677 - val_loss: 0.4669\n",
      "Epoch 3/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 114ms/step - loss: 0.4580 - val_loss: 0.4538\n",
      "Epoch 4/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 114ms/step - loss: 0.4437 - val_loss: 0.4308\n",
      "Epoch 5/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 115ms/step - loss: 0.4044 - val_loss: 0.3890\n",
      "Epoch 6/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m140s\u001B[0m 113ms/step - loss: 0.3728 - val_loss: 0.3737\n",
      "Epoch 7/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 113ms/step - loss: 0.3553 - val_loss: 0.3521\n",
      "Epoch 8/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m93s\u001B[0m 113ms/step - loss: 0.3456 - val_loss: 0.3476\n",
      "Epoch 9/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 113ms/step - loss: 0.3389 - val_loss: 0.3436\n",
      "Epoch 10/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 115ms/step - loss: 0.3354 - val_loss: 0.3422\n",
      "Epoch 11/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m140s\u001B[0m 113ms/step - loss: 0.3336 - val_loss: 0.3405\n",
      "Epoch 12/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 115ms/step - loss: 0.3313 - val_loss: 0.3409\n",
      "Epoch 13/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m93s\u001B[0m 113ms/step - loss: 0.3291 - val_loss: 0.3400\n",
      "Epoch 14/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 114ms/step - loss: 0.3281 - val_loss: 0.3396\n",
      "Epoch 15/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 114ms/step - loss: 0.3276 - val_loss: 0.3371\n",
      "Epoch 16/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 114ms/step - loss: 0.3263 - val_loss: 0.3366\n",
      "Epoch 17/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m140s\u001B[0m 112ms/step - loss: 0.3258 - val_loss: 0.3353\n",
      "Epoch 18/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m144s\u001B[0m 114ms/step - loss: 0.3256 - val_loss: 0.3359\n",
      "Epoch 19/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m139s\u001B[0m 111ms/step - loss: 0.3251 - val_loss: 0.3361\n",
      "Epoch 20/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m144s\u001B[0m 115ms/step - loss: 0.3241 - val_loss: 0.3368\n",
      "Epoch 21/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m93s\u001B[0m 113ms/step - loss: 0.3243 - val_loss: 0.3356\n",
      "Epoch 22/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m93s\u001B[0m 113ms/step - loss: 0.3236 - val_loss: 0.3371\n",
      "Epoch 23/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m141s\u001B[0m 112ms/step - loss: 0.3234 - val_loss: 0.3344\n",
      "Epoch 24/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m144s\u001B[0m 115ms/step - loss: 0.3229 - val_loss: 0.3359\n",
      "Epoch 25/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m139s\u001B[0m 112ms/step - loss: 0.3222 - val_loss: 0.3356\n",
      "Epoch 26/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 113ms/step - loss: 0.3232 - val_loss: 0.3349\n",
      "Epoch 27/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 113ms/step - loss: 0.3225 - val_loss: 0.3366\n",
      "Epoch 28/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m93s\u001B[0m 113ms/step - loss: 0.3227 - val_loss: 0.3350\n",
      "Epoch 29/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m141s\u001B[0m 112ms/step - loss: 0.3218 - val_loss: 0.3359\n",
      "Epoch 30/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 112ms/step - loss: 0.3216 - val_loss: 0.3365\n",
      "Epoch 31/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 113ms/step - loss: 0.3226 - val_loss: 0.3352\n",
      "Epoch 32/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m140s\u001B[0m 111ms/step - loss: 0.3210 - val_loss: 0.3365\n",
      "Epoch 33/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 113ms/step - loss: 0.3209 - val_loss: 0.3347\n",
      "Epoch 34/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m140s\u001B[0m 110ms/step - loss: 0.3215 - val_loss: 0.3357\n",
      "Epoch 35/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m94s\u001B[0m 114ms/step - loss: 0.3216 - val_loss: 0.3353\n",
      "Epoch 36/100\n",
      "\u001B[1m820/820\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m92s\u001B[0m 112ms/step - loss: 0.3214 - val_loss: 0.3356\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-589e6c703d28>\u001B[0m in \u001B[0;36m<cell line: 31>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;31m# Train the model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m model.fit(\n\u001B[0m\u001B[1;32m     32\u001B[0m     \u001B[0;34m[\u001B[0m\u001B[0mencoder_input_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecoder_input_data\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0mdecoder_target_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    317\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mepoch_iterator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcatch_stop_iteration\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    318\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterator\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mepoch_iterator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menumerate_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 319\u001B[0;31m                     \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    320\u001B[0m                     \u001B[0mlogs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m                     \u001B[0mlogs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pythonify_logs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py\u001B[0m in \u001B[0;36mon_train_batch_begin\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m     96\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m     \u001B[0;32mdef\u001B[0m \u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m         \u001B[0mlogs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlogs\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mcallback\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Inference models for testing\n",
    "# Build the encoder model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Build the decoder model\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name='decoder_state_input_h')\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name='decoder_state_input_c')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")\n",
    "\n",
    "# Mapping indices back to words\n",
    "reverse_input_char_index = {v: k for k, v in input_tokenizer.word_index.items()}\n",
    "reverse_target_word_index = {v: k for k, v in output_tokenizer.word_index.items()}\n",
    "\n",
    "# Function to decode the sequence\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1 with only the start token.\n",
    "    target_seq = np.array([output_tokenizer.word_index['<start>']])\n",
    "    target_seq = np.expand_dims(target_seq, 0)\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = reverse_target_word_index.get(sampled_token_index, '')\n",
    "\n",
    "        if sampled_word == '<end>' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += sampled_word + ' '\n",
    "\n",
    "            # Update the target sequence\n",
    "            target_seq = np.array([[sampled_token_index]])\n",
    "\n",
    "            # Update states\n",
    "            states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()"
   ],
   "metadata": {
    "id": "kZ3lprS3tAUP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "9x1ZhG6pc7yZ",
    "outputId": "1ef3bfdd-bd47-4f7d-f32d-bb71fdb1feb3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m 6380/17162\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m59s\u001B[0m 6ms/step - loss: 1.1618"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-30-ffe4adbba6a2>\u001B[0m in \u001B[0;36m<cell line: 85>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[0mdecoder_inputs_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_order_length\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 85\u001B[0;31m history = model.fit([X, decoder_inputs_data], y,\n\u001B[0m\u001B[1;32m     86\u001B[0m                     \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder_masks\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m                     \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    318\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterator\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mepoch_iterator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menumerate_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    319\u001B[0m                     \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 320\u001B[0;31m                     \u001B[0mlogs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    321\u001B[0m                     \u001B[0mlogs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pythonify_logs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    322\u001B[0m                     \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    831\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    832\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 833\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    834\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    835\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    876\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    877\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 878\u001B[0;31m       results = tracing_compilation.call_function(\n\u001B[0m\u001B[1;32m    879\u001B[0m           \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_creation_config\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    880\u001B[0m       )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001B[0m in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m   \u001B[0mbound_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m   \u001B[0mflat_inputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munpack_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbound_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 139\u001B[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m    140\u001B[0m       \u001B[0mflat_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m   )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1320\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1321\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1322\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_inference_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_preflattened\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1323\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001B[0m in \u001B[0;36mcall_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mcall_preflattened\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mSequence\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    215\u001B[0m     \u001B[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 216\u001B[0;31m     \u001B[0mflat_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_flat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    217\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpack_output\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mflat_outputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001B[0m in \u001B[0;36mcall_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mrecord\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstop_recording\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    250\u001B[0m           \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_bound_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 251\u001B[0;31m             outputs = self._bound_context.call_function(\n\u001B[0m\u001B[1;32m    252\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    253\u001B[0m                 \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001B[0m in \u001B[0;36mcall_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1550\u001B[0m     \u001B[0mcancellation_context\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcancellation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcancellation_context\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1552\u001B[0;31m       outputs = execute.execute(\n\u001B[0m\u001B[1;32m   1553\u001B[0m           \u001B[0mname\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"utf-8\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1554\u001B[0m           \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 53\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     54\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     55\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "filtered_data = data[data['expression'] == 'a&b|c&d']\n",
    "print(filtered_data)\n",
    "# write code to get all the rows where data['expression'] == 'a|b&c'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYn-iB9SLwNS",
    "outputId": "dc554606-b34e-4e43-fbc7-733c249a9024"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       expression ordering  bdd_size reordering  bdd_size_reordered\n",
      "4521      a&b|c&d  c:a:d:b        10    c:d:b:a                   5\n",
      "4577      a&b|c&d  a:b:c:d         9    a:b:d:c                   5\n",
      "9532      a&b|c&d  b:c:d:a        10    a:b:c:d                   5\n",
      "14203     a&b|c&d  c:b:a:d        10    a:b:c:d                   5\n",
      "18653     a&b|c&d  b:a:c:d         9    a:b:d:c                   5\n",
      "39999     a&b|c&d  d:b:a:c        10    a:b:d:c                   5\n",
      "42557     a&b|c&d  a:c:d:b        10    a:b:c:d                   5\n",
      "43935     a&b|c&d  c:d:a:b         9    c:d:b:a                   5\n",
      "44120     a&b|c&d  d:c:a:b         9    c:d:b:a                   5\n",
      "44857     a&b|c&d  b:c:a:d        10    a:b:c:d                   5\n",
      "56873     a&b|c&d  a:c:b:d        10    a:b:c:d                   5\n",
      "60023     a&b|c&d  a:b:d:c         9    a:b:d:c                   5\n",
      "67415     a&b|c&d  d:c:b:a         9    c:d:b:a                   5\n",
      "78527     a&b|c&d  b:a:d:c         9    a:b:d:c                   5\n",
      "85209     a&b|c&d  a:d:c:b        10    d:c:b:a                   5\n",
      "87359     a&b|c&d  b:d:c:a        10    c:d:b:a                   5\n",
      "90978     a&b|c&d  c:b:d:a        10    d:c:b:a                   5\n",
      "92026     a&b|c&d  c:a:b:d        10    c:d:b:a                   5\n",
      "93596     a&b|c&d  d:a:c:b        10    d:c:b:a                   5\n",
      "117766    a&b|c&d  d:b:c:a        10    c:d:b:a                   5\n",
      "120900    a&b|c&d  b:d:a:c        10    a:b:d:c                   5\n",
      "124263    a&b|c&d  c:d:b:a         9    c:d:b:a                   5\n",
      "128792    a&b|c&d  a:d:b:c        10    a:b:d:c                   5\n",
      "130362    a&b|c&d  d:a:b:c        10    a:b:d:c                   5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_expression = ['a&b|c&d', 'a&b']\n",
    "test_sequence = input_tokenizer.texts_to_sequences([test_expression])\n",
    "test_sequence = pad_sequences(test_sequence, maxlen=max_encoder_seq_length, padding='post')\n",
    "decoded_ordering = decode_sequence(test_sequence)\n",
    "print('Predicted variable ordering:', decoded_ordering)"
   ],
   "metadata": {
    "id": "YWNQh1lBdA3K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bcf2b666-b778-4ecf-95bc-e0fd13345108"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "Predicted variable ordering: b f a\n"
     ]
    }
   ]
  }
 ]
}
